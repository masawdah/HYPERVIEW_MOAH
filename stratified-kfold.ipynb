{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport zipfile\nfrom xgboost import XGBRegressor\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom skimage import data\nfrom scipy.stats import gmean","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.996049,"end_time":"2022-05-22T16:47:49.317591","exception":false,"start_time":"2022-05-22T16:47:47.321542","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:08:46.810598Z","iopub.execute_input":"2022-06-13T06:08:46.811083Z","iopub.status.idle":"2022-06-13T06:08:48.578057Z","shell.execute_reply.started":"2022-06-13T06:08:46.811045Z","shell.execute_reply":"2022-06-13T06:08:48.576791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Paths\ngt_path = '../input/esahyber/train_data/train_data/train_gt.csv'\nwavelength_path = '../input/esahyber/train_data/train_data/wavelengths.csv'\nhsi_path = '../input/esahyber/train_data/train_data/train_data/1000.npz'\n\ntr_path = \"../input/esahyber/train_data/train_data/train_data\"\nte_path = \"../input/esahyber/test_data/test_data\"","metadata":{"papermill":{"duration":0.046439,"end_time":"2022-05-22T16:47:49.402413","exception":false,"start_time":"2022-05-22T16:47:49.355974","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:08:48.579845Z","iopub.execute_input":"2022-06-13T06:08:48.580209Z","iopub.status.idle":"2022-06-13T06:08:48.585318Z","shell.execute_reply.started":"2022-06-13T06:08:48.580177Z","shell.execute_reply":"2022-06-13T06:08:48.584369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ngt_df = pd.read_csv(gt_path)\nwavelength_df = pd.read_csv(wavelength_path)","metadata":{"papermill":{"duration":0.084775,"end_time":"2022-05-22T16:47:49.523835","exception":false,"start_time":"2022-05-22T16:47:49.43906","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:08:48.586278Z","iopub.execute_input":"2022-06-13T06:08:48.587038Z","iopub.status.idle":"2022-06-13T06:08:48.628046Z","shell.execute_reply.started":"2022-06-13T06:08:48.587007Z","shell.execute_reply":"2022-06-13T06:08:48.627167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Displaying one hyperspectral band","metadata":{"papermill":{"duration":0.036483,"end_time":"2022-05-22T16:47:49.596993","exception":false,"start_time":"2022-05-22T16:47:49.56051","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(10, 5))\nband_id = 100\nwavelength = wavelength_df.loc[band_id-1]\n\nwith np.load(hsi_path) as npz:\n    arr = np.ma.MaskedArray(**npz)\n\naxs[0].imshow(arr[band_id,:,:].data)\naxs[1].imshow(arr[band_id,:,:])\nplt.suptitle(f'Representation of band {int(wavelength[\"band_no\"])} ({wavelength[\"wavelength\"]} nm)', fontsize=15)\nplt.show()","metadata":{"papermill":{"duration":0.427921,"end_time":"2022-05-22T16:47:50.060946","exception":false,"start_time":"2022-05-22T16:47:49.633025","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:08:48.629706Z","iopub.execute_input":"2022-06-13T06:08:48.630753Z","iopub.status.idle":"2022-06-13T06:08:49.067473Z","shell.execute_reply.started":"2022-06-13T06:08:48.6307Z","shell.execute_reply":"2022-06-13T06:08:49.066223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Displaying the aggregated spectral curve for a field","metadata":{"papermill":{"duration":0.039366,"end_time":"2022-05-22T16:47:50.138691","exception":false,"start_time":"2022-05-22T16:47:50.099325","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 5))\n\nmasked_scene_mean_spectral_reflectance = [arr[i,:,:].mean() for i in range(arr.shape[0])]\nfull_scene_mean_spectral_reflectance = [arr[i,:,:].data.mean() for i in range(arr.shape[0])]\n\nplt.plot(wavelength_df['wavelength'], full_scene_mean_spectral_reflectance, label='Full image')\nplt.plot(wavelength_df['wavelength'], masked_scene_mean_spectral_reflectance, label='Masked image')\n\nplt.xlabel('[nm]')\nplt.legend()\nplt.title(f'Average reflectance ({hsi_path.split(\"/\")[-1]})')\nplt.show()","metadata":{"papermill":{"duration":0.266116,"end_time":"2022-05-22T16:47:50.442419","exception":false,"start_time":"2022-05-22T16:47:50.176303","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:08:49.069429Z","iopub.execute_input":"2022-06-13T06:08:49.069914Z","iopub.status.idle":"2022-06-13T06:08:49.316262Z","shell.execute_reply.started":"2022-06-13T06:08:49.069867Z","shell.execute_reply":"2022-06-13T06:08:49.315167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the data","metadata":{"papermill":{"duration":0.039362,"end_time":"2022-05-22T16:47:50.520911","exception":false,"start_time":"2022-05-22T16:47:50.481549","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class SpectralCurveFiltering():\n    \"\"\"\n    Create a histogram (a spectral curve) of a 3D cube, using the merge_function\n    to aggregate all pixels within one band. The return array will have\n    the shape of [CHANNELS_COUNT]\n    \"\"\"\n\n    def __init__(self, merge_function = np.mean):\n        self.merge_function = merge_function\n\n    def __call__(self, sample: np.ndarray):\n        return self.merge_function(sample.data, axis=(1, 2))","metadata":{"papermill":{"duration":0.048394,"end_time":"2022-05-22T16:47:50.608116","exception":false,"start_time":"2022-05-22T16:47:50.559722","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:08:49.317777Z","iopub.execute_input":"2022-06-13T06:08:49.318256Z","iopub.status.idle":"2022-06-13T06:08:49.327328Z","shell.execute_reply.started":"2022-06-13T06:08:49.31822Z","shell.execute_reply":"2022-06-13T06:08:49.326326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(directory: str, merge_functions, wv, prefixes):\n    \"\"\"Load each cube, reduce its dimensionality and append to array.\n\n    Args:\n        directory (str): Directory to either train or test set\n    Returns:\n        [type]: A list with spectral curve for each sample.\n    \"\"\"\n    hsi_data = None\n    for idx, merge_function in enumerate(merge_functions):\n      data = []\n      filtering = SpectralCurveFiltering(merge_function = merge_function)\n      all_files = np.array(\n          sorted(\n              glob(os.path.join(directory, \"*.npz\")),\n              key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n          )\n      )\n      for file_name in all_files:\n          with np.load(file_name) as npz:\n              arr = np.ma.MaskedArray(**npz)\n                \n          # Standard Normal Variate (SNV)\n          #arr = NormBand(arr)\n          #arr1 = arr.data * 10e-5\n          #arr = np.ma.masked_array(arr1,arr.mask)\n          arr = filtering(arr)\n          data.append(arr)\n\n      data = np.array(data)\n      #data = pd.DataFrame(data,columns=[wv], dtype=np.float64)\n      data = pd.DataFrame(data,columns=wv, dtype=np.float64)\n      data = data.add_prefix(f'{prefixes[idx]}_wv_')\n      if hsi_data is None:\n        hsi_data = data #pd.DataFrame(data)\n      else:\n        hsi_data = pd.concat([hsi_data, data], axis=1)\n\n    return hsi_data\n\n\ndef load_gt(file_path: str):\n    \"\"\"Load labels for train set from the ground truth file.\n    Args:\n        file_path (str): Path to the ground truth .csv file.\n    Returns:\n        [type]: 2D numpy array with soil properties levels\n    \"\"\"\n    gt_file = pd.read_csv(file_path)\n    labels = gt_file[[\"P\", \"K\", \"Mg\", \"pH\"]].values\n    return labels\n\n","metadata":{"papermill":{"duration":0.05384,"end_time":"2022-05-22T16:47:50.700816","exception":false,"start_time":"2022-05-22T16:47:50.646976","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:08:49.32893Z","iopub.execute_input":"2022-06-13T06:08:49.329329Z","iopub.status.idle":"2022-06-13T06:08:49.34312Z","shell.execute_reply.started":"2022-06-13T06:08:49.329282Z","shell.execute_reply":"2022-06-13T06:08:49.34225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prefixes = ['mean']#, 'std'] # , 'min', 'max']\nmerge_functions = [np.mean]#, np.std] #, np.min, np.max]\nwv = (list(wavelength_df['wavelength']))\nX_tr = load_data(tr_path, merge_functions, wv, prefixes)","metadata":{"papermill":{"duration":70.072114,"end_time":"2022-05-22T16:49:00.812147","exception":false,"start_time":"2022-05-22T16:47:50.740033","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:08:49.344231Z","iopub.execute_input":"2022-06-13T06:08:49.344626Z","iopub.status.idle":"2022-06-13T06:10:00.673811Z","shell.execute_reply.started":"2022-06-13T06:08:49.344592Z","shell.execute_reply":"2022-06-13T06:10:00.672684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_te = load_data(te_path, merge_functions, wv, prefixes)","metadata":{"papermill":{"duration":48.259689,"end_time":"2022-05-22T16:49:49.111962","exception":false,"start_time":"2022-05-22T16:49:00.852273","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:10:00.676586Z","iopub.execute_input":"2022-06-13T06:10:00.67696Z","iopub.status.idle":"2022-06-13T06:10:47.917056Z","shell.execute_reply.started":"2022-06-13T06:10:00.676928Z","shell.execute_reply":"2022-06-13T06:10:47.91585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = load_gt(gt_path)\n\ny = pd.DataFrame(y, columns=[\"P\", \"K\", \"Mg\", \"pH\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T06:10:47.919066Z","iopub.execute_input":"2022-06-13T06:10:47.919491Z","iopub.status.idle":"2022-06-13T06:10:47.937803Z","shell.execute_reply.started":"2022-06-13T06:10:47.919454Z","shell.execute_reply":"2022-06-13T06:10:47.936912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tr.head(3)","metadata":{"papermill":{"duration":0.081717,"end_time":"2022-05-22T16:49:49.236392","exception":false,"start_time":"2022-05-22T16:49:49.154675","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-12T21:10:11.163535Z","iopub.execute_input":"2022-06-12T21:10:11.163958Z","iopub.status.idle":"2022-06-12T21:10:11.196442Z","shell.execute_reply.started":"2022-06-12T21:10:11.16392Z","shell.execute_reply":"2022-06-12T21:10:11.195429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prefixes = ['std', 'min', 'max', 'median']\nmerge_functions = [np.std, np.min, np.max, np.median]\nwv = (list(wavelength_df['wavelength']))\nX_tr_stats = load_data(tr_path, merge_functions, wv, prefixes)\n\nX_te_stats = load_data(te_path, merge_functions, wv, prefixes)","metadata":{"papermill":{"duration":252.885151,"end_time":"2022-05-22T16:54:02.160151","exception":false,"start_time":"2022-05-22T16:49:49.275","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-13T06:10:47.939836Z","iopub.execute_input":"2022-06-13T06:10:47.940321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Narrow bands Indices","metadata":{"papermill":{"duration":0.04137,"end_time":"2022-05-22T16:54:02.244477","exception":false,"start_time":"2022-05-22T16:54:02.203107","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Indices of important features\ndef NBI(df, features):\n  X_indices = None\n  names = []\n  for col1 in features:\n    indices = []\n    for col2 in features:\n      if col1 !=col2:\n        name = f'Index_{col1}_{col2}'\n        #name2 = f'{col1}_multi_{col2}'\n        #name3 =  f'{col1}_div_{col2}'\n\n        index = (np.array(df[col2]) - np.array(df[col1])) / (np.array(df[col2]) + np.array(df[col1]))\n        names.append(name)\n\n        indices.append(pd.DataFrame(index, columns=[name]))\n\n        #multi = np.array(df[col2]) * np.array(df[col1])\n        #names.append(name2)\n        #indices.append(pd.DataFrame(multi, columns=[name2]))\n\n\n        #divi = np.array(df[col2]) / np.array(df[col1])\n        #names.append(name3)\n        #indices.append(pd.DataFrame(divi, columns=[name3]))\n\n    X_new_indices = pd.concat(indices, axis=1)\n\n    if X_indices is None:\n      X_indices = X_new_indices\n    else:\n      X_indices = pd.concat([X_indices, X_new_indices] , axis=1, ignore_index=False)\n\n  return  X_indices","metadata":{"papermill":{"duration":0.05356,"end_time":"2022-05-22T16:54:02.337493","exception":false,"start_time":"2022-05-22T16:54:02.283933","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All possible band combinations\nfeatures = X_tr.columns\n\nX_tr_indices = NBI(X_tr, features)\nX_te_indices = NBI(X_te, features)","metadata":{"papermill":{"duration":122.204043,"end_time":"2022-05-22T16:56:04.580643","exception":false,"start_time":"2022-05-22T16:54:02.3766","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tr = pd.concat([X_tr, X_tr_indices] , axis=1, ignore_index=False)\nX_te = pd.concat([X_te, X_te_indices] , axis=1, ignore_index=False)\n\nprint(X_tr.shape)\nprint(X_te.shape)","metadata":{"papermill":{"duration":1.756717,"end_time":"2022-05-22T16:56:06.376701","exception":false,"start_time":"2022-05-22T16:56:04.619984","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tr = pd.concat([X_tr, X_tr_stats] , axis=1, ignore_index=False)\nX_te = pd.concat([X_te, X_te_stats] , axis=1, ignore_index=False)\n\nprint(X_tr.shape)\nprint(X_te.shape)","metadata":{"papermill":{"duration":1.545576,"end_time":"2022-05-22T16:56:07.962441","exception":false,"start_time":"2022-05-22T16:56:06.416865","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Selection","metadata":{"papermill":{"duration":0.039541,"end_time":"2022-05-22T16:56:08.042125","exception":false,"start_time":"2022-05-22T16:56:08.002584","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nimport pickle","metadata":{"papermill":{"duration":0.20651,"end_time":"2022-05-22T16:56:08.287719","exception":false,"start_time":"2022-05-22T16:56:08.081209","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with open('../input/best-var-lists/P_selected_features.pkl', 'rb') as f:\n#    P_selected_features = pickle.load(f)\n    \n#with open('../input/best-var-lists/K_selected_features.pkl', 'rb') as f:\n #   K_selected_features = pickle.load(f)\n    \n#with open('../input/best-var-lists/Mg_selected_features.pkl', 'rb') as f:\n #   Mg_selected_features = pickle.load(f)\n    \n#with open('../input/best-var-lists/pH_selected_features.pkl', 'rb') as f:\n  #  pH_selected_features = pickle.load(f)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe = RFE(estimator=RandomForestRegressor(n_estimators=100,random_state=2022), n_features_to_select=500, step=0.40)\nmodel = RandomForestRegressor(n_estimators=100, random_state=2022)\npipeline = Pipeline(steps=[('s',rfe),('m',model)])\n\npipeline.fit(X_tr, y['P'])\n\ncols = list(X_tr.columns)\nP_selected_features = []\nfor idx, col in enumerate(cols):\n    if rfe.support_[idx]:\n        P_selected_features.append(col)\n        \n\nwith open('P_selected_features.pkl', 'wb') as f:\n    pickle.dump(P_selected_features, f)\n    \n    ","metadata":{"papermill":{"duration":6045.552752,"end_time":"2022-05-22T18:36:53.971475","exception":false,"start_time":"2022-05-22T16:56:08.418723","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-07T18:53:25.105478Z","iopub.execute_input":"2022-06-07T18:53:25.105982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe = RFE(estimator=RandomForestRegressor(n_estimators=100,random_state=2022), n_features_to_select=500, step=0.40)\nmodel = RandomForestRegressor(n_estimators=100, random_state=2022)\npipeline = Pipeline(steps=[('s',rfe),('m',model)])\n\npipeline.fit(X_tr, y['K'])\n\ncols = list(X_tr.columns)\nK_selected_features = []\nfor idx, col in enumerate(cols):\n    if rfe.support_[idx]:\n        K_selected_features.append(col)\n        \nwith open('K_selected_features.pkl', 'wb') as f:\n    pickle.dump(K_selected_features, f)\n    ","metadata":{"papermill":{"duration":5311.855657,"end_time":"2022-05-22T20:05:25.870128","exception":false,"start_time":"2022-05-22T18:36:54.014471","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe = RFE(estimator=RandomForestRegressor(n_estimators=100,random_state=2022), n_features_to_select=500, step=0.40)\nmodel = RandomForestRegressor(n_estimators=100, random_state=2022)\npipeline = Pipeline(steps=[('s',rfe),('m',model)])\n\npipeline.fit(X_tr, y['Mg'])\n\ncols = list(X_tr.columns)\nMg_selected_features = []\nfor idx, col in enumerate(cols):\n    if rfe.support_[idx]:\n        Mg_selected_features.append(col)\n        \nwith open('Mg_selected_features.pkl', 'wb') as f:\n    pickle.dump(Mg_selected_features, f)","metadata":{"execution":{"iopub.execute_input":"2022-05-22T20:05:26.099388Z","iopub.status.busy":"2022-05-22T20:05:26.098971Z","iopub.status.idle":"2022-05-22T21:28:16.918488Z","shell.execute_reply":"2022-05-22T21:28:16.916641Z"},"papermill":{"duration":4970.876836,"end_time":"2022-05-22T21:28:16.93046","exception":false,"start_time":"2022-05-22T20:05:26.053624","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe = RFE(estimator=RandomForestRegressor(n_estimators=100,random_state=2022), n_features_to_select=500, step=0.40)\nmodel = RandomForestRegressor(n_estimators=100, random_state=2022)\npipeline = Pipeline(steps=[('s',rfe),('m',model)])\n\npipeline.fit(X_tr, y['pH'])\n\ncols = list(X_tr.columns)\npH_selected_features = []\nfor idx, col in enumerate(cols):\n    if rfe.support_[idx]:\n        pH_selected_features.append(col)\n        \n        \nwith open('pH_selected_features.pkl', 'wb') as f:\n    pickle.dump(pH_selected_features, f)","metadata":{"execution":{"iopub.execute_input":"2022-05-22T21:28:17.030803Z","iopub.status.busy":"2022-05-22T21:28:17.030221Z","iopub.status.idle":"2022-05-22T22:44:34.92002Z","shell.execute_reply":"2022-05-22T22:44:34.918122Z"},"papermill":{"duration":4577.946355,"end_time":"2022-05-22T22:44:34.932162","exception":false,"start_time":"2022-05-22T21:28:16.985807","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"P_X_tr = X_tr[P_selected_features]\nP_X_te = X_te[P_selected_features]\n\nK_X_tr = X_tr[K_selected_features]\nK_X_te = X_te[K_selected_features]\n\nMg_X_tr = X_tr[Mg_selected_features]\nMg_X_te = X_te[Mg_selected_features]\n\npH_X_tr = X_tr[pH_selected_features]\npH_X_te = X_te[pH_selected_features]","metadata":{"papermill":{"duration":0.971935,"end_time":"2022-05-22T22:44:39.244661","exception":false,"start_time":"2022-05-22T22:44:38.272726","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Interactions","metadata":{}},{"cell_type":"code","source":"# Indices of important features\ndef interactions(df, features):\n    X_interact = None\n    names = []\n    p_columns = []\n    for col1 in features:\n        interact = []\n        p_columns.append(col1)\n       # print(p_columns)\n\n        for col2 in features:\n            if col2 not in p_columns:\n                #print(col2)\n                \n                name = f'{col1}_multi_{col2}'\n                name2 =  f'{col1}_div_{col2}'\n                multi = np.array(df[col2]) * np.array(df[col1])\n                names.append(name)\n                interact.append(pd.DataFrame(multi, columns=[name]))\n\n\n                divi = np.array(df[col2]) / np.array(df[col1] + 1e-6)\n                names.append(name2)\n                interact.append(pd.DataFrame(divi, columns=[name2]))\n        #print('-----------------')\n        if len(p_columns) != len(features):\n            X_new_interact = pd.concat(interact, axis=1)\n\n            if X_interact is None:\n                X_interact = X_new_interact\n            else:\n                X_interact = pd.concat([X_interact, X_new_interact] , axis=1, ignore_index=False)\n\n    return  X_interact","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All possible band combinations\nfeatures = P_X_tr.columns[:10]\n\nX_tr_intrs = interactions(P_X_tr[features], features)\nX_te_intrs = interactions(P_X_te[features], features)\n\nP_X_tr = pd.concat([P_X_tr, X_tr_intrs] , axis=1, ignore_index=False)\nP_X_te = pd.concat([P_X_te, X_te_intrs] , axis=1, ignore_index=False)\n\nprint(P_X_tr.shape)\nprint(P_X_te.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All possible band combinations\nfeatures = K_X_tr.columns[:10]\n\nX_tr_intrs = interactions(K_X_tr[features], features)\nX_te_intrs = interactions(K_X_te[features], features)\n\nK_X_tr = pd.concat([K_X_tr, X_tr_intrs] , axis=1, ignore_index=False)\nK_X_te = pd.concat([K_X_te, X_te_intrs] , axis=1, ignore_index=False)\n\nprint(K_X_tr.shape)\nprint(K_X_te.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All possible band combinations\nfeatures = Mg_X_tr.columns[:10]\n\nX_tr_intrs = interactions(Mg_X_tr[features], features)\nX_te_intrs = interactions(Mg_X_te[features], features)\n\nMg_X_tr = pd.concat([Mg_X_tr, X_tr_intrs] , axis=1, ignore_index=False)\nMg_X_te = pd.concat([Mg_X_te, X_te_intrs] , axis=1, ignore_index=False)\n\nprint(Mg_X_tr.shape)\nprint(Mg_X_te.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All possible band combinations\nfeatures = pH_X_tr.columns[:10]\n\nX_tr_intrs = interactions(pH_X_tr[features], features)\nX_te_intrs = interactions(pH_X_te[features], features)\n\npH_X_tr = pd.concat([pH_X_tr, X_tr_intrs] , axis=1, ignore_index=False)\npH_X_te = pd.concat([pH_X_te, X_te_intrs] , axis=1, ignore_index=False)\n\nprint(pH_X_tr.shape)\nprint(pH_X_te.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generating baseline solution","metadata":{"papermill":{"duration":0.041717,"end_time":"2022-05-22T22:44:35.030557","exception":false,"start_time":"2022-05-22T22:44:34.98884","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\nimport math\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"P_data = pd.concat([P_X_tr, y['P']], axis=1).reset_index(drop=True)\nK_data = pd.concat([K_X_tr, y['K']], axis=1).reset_index(drop=True)\nMg_data = pd.concat([Mg_X_tr, y['Mg']], axis=1).reset_index(drop=True)\npH_data = pd.concat([pH_X_tr, y['pH']], axis=1).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def skf_split(data_df, target):\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2022)\n    num_splits = 5\n    num_bins = math.floor(len(data_df) / num_splits)  # num of bins to be created\n    bins_on = data_df[target]  # variable to be used for stratification\n    qc = pd.cut(bins_on.tolist(), num_bins)  # divides data in bins\n    data_df['bins'] = qc.codes\n    \n    val_index = []\n    X_train, X_val = [], []\n    Y_train, Y_val = [], []\n    for idx , (train, val) in enumerate(skf.split(data_df,data_df['bins'])):\n        x_train, x_val, y_train, y_val = data_df.iloc[train], data_df.iloc[val], data_df[target].iloc[train], data_df[target].iloc[val]\n        x_train = x_train.drop(['bins', target], axis=1)\n        x_val = x_val.drop(['bins', target], axis=1)\n        \n        val_index.append(val)\n        X_train.append(x_train)\n        Y_train.append(y_train)\n        \n        X_val.append(x_val)\n        Y_val.append(y_val)\n    \n    return X_train, X_val, Y_train, Y_val, val_index","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:26:52.223224Z","iopub.execute_input":"2022-06-12T22:26:52.223917Z","iopub.status.idle":"2022-06-12T22:26:52.234182Z","shell.execute_reply.started":"2022-06-12T22:26:52.223875Z","shell.execute_reply":"2022-06-12T22:26:52.232847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_P_tr,X_P_val, y_P_tr, y_P_val, P_val_index = skf_split(P_data, 'P')\nX_K_tr,X_K_val, y_K_tr, y_K_val, K_val_index = skf_split(K_data, 'K')\nX_Mg_tr,X_Mg_val, y_Mg_tr, y_Mg_val, Mg_val_index = skf_split(Mg_data, 'Mg')\nX_pH_tr,X_pH_val, y_pH_tr, y_pH_val, pH_val_index = skf_split(pH_data, 'pH')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:26:54.09535Z","iopub.execute_input":"2022-06-12T22:26:54.095767Z","iopub.status.idle":"2022-06-12T22:26:54.290358Z","shell.execute_reply.started":"2022-06-12T22:26:54.095734Z","shell.execute_reply":"2022-06-12T22:26:54.288568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor\nimport random","metadata":{"papermill":{"duration":2.880186,"end_time":"2022-05-22T22:44:37.951619","exception":false,"start_time":"2022-05-22T22:44:35.071433","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-12T22:11:52.212042Z","iopub.execute_input":"2022-06-12T22:11:52.212926Z","iopub.status.idle":"2022-06-12T22:11:52.21699Z","shell.execute_reply.started":"2022-06-12T22:11:52.212883Z","shell.execute_reply":"2022-06-12T22:11:52.216143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation metric\nclass BaselineRegressor:\n    \"\"\"\n    Baseline regressor, which calculates the mean value of the target from the training\n    data and returns it for each testing sample.\n    \"\"\"\n    def __init__(self):\n        self.mean = 0\n\n    def fit(self, X_train: np.ndarray, y_train: np.ndarray):\n      self.mean = np.mean(y_train, axis=0)\n      #self.classes_count = y_train.shape[1]\n      self.classes_count = 1\n      return self\n\n    def predict(self, X_test: np.ndarray):\n      return np.full((len(X_test), self.classes_count), self.mean)\n","metadata":{"papermill":{"duration":0.055446,"end_time":"2022-05-22T22:44:38.047016","exception":false,"start_time":"2022-05-22T22:44:37.99157","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-12T22:11:53.965959Z","iopub.execute_input":"2022-06-12T22:11:53.966695Z","iopub.status.idle":"2022-06-12T22:11:53.972609Z","shell.execute_reply.started":"2022-06-12T22:11:53.96665Z","shell.execute_reply":"2022-06-12T22:11:53.971683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:11:56.576163Z","iopub.execute_input":"2022-06-12T22:11:56.57657Z","iopub.status.idle":"2022-06-12T22:11:59.051531Z","shell.execute_reply.started":"2022-06-12T22:11:56.576536Z","shell.execute_reply":"2022-06-12T22:11:59.05051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def EvaluationMetric(baseline_reg, x_val, y_val, rf_val_preds, cat_val_preds, lgbm_val_preds, xgbm_val_preds, et_val_preds,\n                     rf_te_preds, cat_te_preds, lgbm_te_preds, xgbm_te_preds, et_te_preds):\n    #baseline_model = baseline_reg\n    baseline_predictions = baseline_reg.predict(x_val)\n    baseline_predictions = baseline_predictions.squeeze()\n    baselines = np.mean((y_val - baseline_predictions) ** 2, axis=0)\n    \n    # Calculate MSE\n    best_score = np.inf\n    for i in range(5000):\n        weights = np.random.dirichlet(np.ones(5),size=1)\n        a = weights[0][0]\n        b = weights[0][1]\n        c = weights[0][2]\n        d = weights[0][3]\n        e = weights[0][4]\n        \n        val_preds = (a * rf_val_preds) + (b * cat_val_preds) + (c * lgbm_val_preds) + (d * xgbm_val_preds) + (e * et_val_preds)\n        mse = np.mean((y_val - val_preds) ** 2, axis=0)\n        score = mse / baselines\n        \n        if score < best_score:\n            #print(score)\n            best_score = score\n            best_a = a\n            best_b = b\n            best_c = c\n            best_d = d\n            best_e = e\n    val_preds = (best_a * rf_val_preds) + (best_b * cat_val_preds) + (best_c * lgbm_val_preds) + (best_d * xgbm_val_preds) + (best_e * et_val_preds)\n    te_preds = (best_a * rf_te_preds) + (best_b * cat_te_preds) + (best_c * lgbm_te_preds) + (best_d * xgbm_te_preds) + (best_e * et_te_preds)\n    \n    \n    # Calculate the final score\n    #final_score = np.mean(scores)\n\n    return best_score, te_preds, val_preds","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:12:01.977115Z","iopub.execute_input":"2022-06-12T22:12:01.977521Z","iopub.status.idle":"2022-06-12T22:12:01.987706Z","shell.execute_reply.started":"2022-06-12T22:12:01.977486Z","shell.execute_reply":"2022-06-12T22:12:01.986871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def regressor(x_train, y_train, x_val, y_val, X_test):\n    rf_regressor = RandomForestRegressor(random_state=2022, criterion='squared_error', n_estimators=700)\n    rf_regressor.fit(x_train,y_train)\n    rf_val_preds =  rf_regressor.predict(x_val)\n    rf_te_preds = rf_regressor.predict(X_test)\n\n    \n    cat_regressor = CatBoostRegressor(n_estimators=3000,learning_rate=0.01,logging_level='Silent',random_state=2022, early_stopping_rounds=300)\n    cat_regressor.fit(x_train,y_train)\n    cat_val_preds =  cat_regressor.predict(x_val)\n    cat_te_preds = cat_regressor.predict(X_test)\n\n    \n    \n    lgbm_regressor = LGBMRegressor(learning_rate=0.01, n_estimators=3000,deterministic=True,random_state=2022, n_jobs=- 1) #,subsample=0.65,subsample_freq=20, colsample_bytree=0.65,\n    lgbm_regressor.fit(x_train,y_train)\n    lgbm_val_preds =  lgbm_regressor.predict(x_val)\n    lgbm_te_preds = lgbm_regressor.predict(X_test)\n\n    \n    xgbm_regressor =XGBRegressor(n_estimators = 2000,learning_rate = 0.01,seed=2022,random_state = 2022)\n    xgbm_regressor.fit(x_train,y_train)\n    xgbm_val_preds =  xgbm_regressor.predict(x_val)\n    xgbm_te_preds = xgbm_regressor.predict(X_test)\n\n    \n    et_regressor = ExtraTreesRegressor(n_estimators=700,criterion = \"squared_error\",\n                                       random_state=2022) # bootstrap = True, max_samples = 0.85, warm_start=True,\n    et_regressor.fit(x_train,y_train)\n    et_val_preds =  et_regressor.predict(x_val)\n    et_te_preds = et_regressor.predict(X_test)\n\n    \n\n    # Predictions\n    baseline_reg = BaselineRegressor()\n    baseline_reg = baseline_reg.fit(x_train, y_train)\n    \n    score, te_preds, train_preds = EvaluationMetric(baseline_reg, x_val, y_val, rf_val_preds, cat_val_preds,lgbm_val_preds, xgbm_val_preds,et_val_preds,\n                                       rf_te_preds, cat_te_preds, lgbm_te_preds, xgbm_te_preds, et_te_preds)\n\n    # train predictions\n    #train_preds = regressor.predict(x_val)\n\n    # Test predictions\n    #preds = regressor.predict(X_test)\n\n    return score, te_preds , train_preds","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:12:04.982245Z","iopub.execute_input":"2022-06-12T22:12:04.982613Z","iopub.status.idle":"2022-06-12T22:12:04.993234Z","shell.execute_reply.started":"2022-06-12T22:12:04.982582Z","shell.execute_reply":"2022-06-12T22:12:04.992275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(2022)\n\n#kf = KFold(n_splits =5,shuffle=True,random_state=2022)\n\nfinal_scores = []\n#val_predictions = []\nfinal_predictions = []\ntrain_preds = np.zeros((X_tr.shape[0],4)) \n\nfor i, s in enumerate(range(5)):\n    print(f'######### FOLD {i+1} / 5')\n    scores = []\n    preds = np.zeros((X_te.shape[0],4))\n\n    # Predict P \n    x_train, x_val, y_train,  y_val = X_P_tr[s], X_P_val[s], y_P_tr[s], y_P_val[s]\n    score, P_preds , P_train_preds = regressor(x_train, y_train, x_val, y_val, P_X_te)\n    scores.append(score)\n    print(f'P Score: {score}')\n    train_preds[P_val_index[s],0] = P_train_preds\n    preds[:,0] = P_preds\n    \n\n    # Predict k\n    x_train, x_val, y_train,  y_val = X_K_tr[s], X_K_val[s], y_K_tr[s], y_K_val[s]\n    score,  k_preds, k_train_preds = regressor(x_train, y_train, x_val, y_val, K_X_te)\n    scores.append(score)\n    print(f'K Score: {score}')\n    train_preds[K_val_index[s],1] = k_train_preds\n    preds[:,1] =k_preds\n    \n\n    # Predict Mg\n    x_train, x_val, y_train,  y_val = X_Mg_tr[s], X_Mg_val[s], y_Mg_tr[s], y_Mg_val[s]\n    score, Mg_preds, Mg_train_preds = regressor(x_train, y_train, x_val, y_val, Mg_X_te)\n    scores.append(score)\n    print(f'Mg Score: {score}')\n    train_preds[Mg_val_index[s],2] = Mg_train_preds\n    preds[:,2] = Mg_preds\n\n\n    # Predict pH\n    x_train, x_val, y_train,  y_val = X_pH_tr[s], X_pH_val[s], y_pH_tr[s], y_pH_val[s]\n    score, pH_preds, pH_train_preds = regressor(x_train, y_train, x_val, y_val, pH_X_te)\n    scores.append(score)\n    print(f'pH Score: {score}')\n    train_preds[pH_val_index[s],3] = pH_train_preds\n    preds[:,3] = pH_preds\n\n    final_score = np.mean(scores)\n    print(f'Overall score: {final_score} ')\n\n    final_scores.append(final_score)\n\n    final_predictions.append(preds)\n\n\nprint('mean scores: {} '.format(np.mean(final_scores)))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:28:25.678357Z","iopub.execute_input":"2022-06-12T22:28:25.678785Z","iopub.status.idle":"2022-06-12T22:46:16.353939Z","shell.execute_reply.started":"2022-06-12T22:28:25.67875Z","shell.execute_reply":"2022-06-12T22:46:16.352546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_train_preds = pd.DataFrame(data = train_preds, columns=[\"P\", \"K\", \"Mg\", \"pH\"])\n\nf_train_preds.to_csv(\"./train_preds.csv\", index_label=\"sample_index\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test_predictions = gmean(final_predictions, axis=0)\n\nsubmission = pd.DataFrame(data = final_test_predictions, columns=[\"P\", \"K\", \"Mg\", \"pH\"])\nsubmission.to_csv(\"./submissions_gmean_cat_rf_lgbm_xgbm_et.csv\", index_label=\"sample_index\")","metadata":{},"execution_count":null,"outputs":[]}]}